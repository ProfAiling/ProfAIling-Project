{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries.\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from spacy import tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tkz = tokenizer.Tokenizer(nlp.vocab)\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import unicodedata\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "\n",
    "#### We import *embedding*, containing posts, embedding and labels, and *features*, containing the features we extracted in the corresponding notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.12765062, -0.008142131, -0.02058363, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.07554571, -0.01604788, 0.037005804, 0.0478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.054309648, 0.120382324, 0.01667131, 0.0222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.044570502, -0.11837147, 0.018605148, 0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.014926629, 0.058680117, 0.10058031, 0.0757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526806</th>\n",
       "      <td>[-0.04391508, -0.04225395, 0.008524458, -0.069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>[-0.027237782, 0.041711215, 0.074862875, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>[-0.023386871, -0.043085545, -0.034292, 0.0733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>[-0.003149762, 0.06911602, 0.060416125, 0.0145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>[-0.0021229745, -0.004084602, 0.040437568, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480383 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                embedding\n",
       "1       [-0.12765062, -0.008142131, -0.02058363, -0.05...\n",
       "2       [-0.07554571, -0.01604788, 0.037005804, 0.0478...\n",
       "3       [-0.054309648, 0.120382324, 0.01667131, 0.0222...\n",
       "4       [-0.044570502, -0.11837147, 0.018605148, 0.028...\n",
       "5       [-0.014926629, 0.058680117, 0.10058031, 0.0757...\n",
       "...                                                   ...\n",
       "526806  [-0.04391508, -0.04225395, 0.008524458, -0.069...\n",
       "526807  [-0.027237782, 0.041711215, 0.074862875, -0.03...\n",
       "526809  [-0.023386871, -0.043085545, -0.034292, 0.0733...\n",
       "526810  [-0.003149762, 0.06911602, 0.060416125, 0.0145...\n",
       "526811  [-0.0021229745, -0.004084602, 0.040437568, 0.0...\n",
       "\n",
       "[480383 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1 = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/SL-Final-Project/embedding_200mila.pkl')\n",
    "embedding1 = embedding1[['embedding']]\n",
    "\n",
    "embedding2 = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/SL-Final-Project/embedding_300mila.pkl')\n",
    "embedding2 = embedding2[['embedding']]\n",
    "\n",
    "embedding = pd.concat([embedding1, embedding2], ignore_index=False)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_class</th>\n",
       "      <th>word_count</th>\n",
       "      <th>has_emoticon</th>\n",
       "      <th>has_punctuation</th>\n",
       "      <th>has_hope</th>\n",
       "      <th>has_hehe</th>\n",
       "      <th>has_weeks</th>\n",
       "      <th>...</th>\n",
       "      <th>has_taking</th>\n",
       "      <th>has_bill</th>\n",
       "      <th>has_hey</th>\n",
       "      <th>has_saturday</th>\n",
       "      <th>has_remember</th>\n",
       "      <th>has_party</th>\n",
       "      <th>has_walking</th>\n",
       "      <th>has_share</th>\n",
       "      <th>has_brother</th>\n",
       "      <th>has_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ooh shiny commenting</td>\n",
       "      <td>ooh shiny commenting</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wuts parade suked band battle kicked ass jims ...</td>\n",
       "      <td>wuts parade suked band battle kicked ass jims ...</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anymore concerned everyday bold faced liar ahe...</td>\n",
       "      <td>anymore concerned everyday bold faced liar ahe...</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roof sunset posted paul</td>\n",
       "      <td>roof sunset posted paul</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gawd luv nanny absolutely greatest woman earth...</td>\n",
       "      <td>gawd luv nanny absolutely greatest woman earth...</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526807</th>\n",
       "      <td>write injuries sand kindnesses marble french p...</td>\n",
       "      <td>write injuries sand kindnesses marble french p...</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526808</th>\n",
       "      <td>wes dad stan</td>\n",
       "      <td>wes dad stan</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526809</th>\n",
       "      <td>prefer calling nice guy fact obviously carried...</td>\n",
       "      <td>prefer calling nice guy fact obviously carried...</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526810</th>\n",
       "      <td>angela othello noah shaved head short hair sho...</td>\n",
       "      <td>angela othello noah shaved head short hair sho...</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526811</th>\n",
       "      <td>keeping short busy wasting ways online hobbies...</td>\n",
       "      <td>keeping short busy wasting ways online hobbies...</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503897 rows Ã— 547 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "0                                    ooh shiny commenting   \n",
       "1       wuts parade suked band battle kicked ass jims ...   \n",
       "2       anymore concerned everyday bold faced liar ahe...   \n",
       "3                                 roof sunset posted paul   \n",
       "4       gawd luv nanny absolutely greatest woman earth...   \n",
       "...                                                   ...   \n",
       "526807  write injuries sand kindnesses marble french p...   \n",
       "526808                                       wes dad stan   \n",
       "526809  prefer calling nice guy fact obviously carried...   \n",
       "526810  angela othello noah shaved head short hair sho...   \n",
       "526811  keeping short busy wasting ways online hobbies...   \n",
       "\n",
       "                                               clean_post  gender  age_class  \\\n",
       "0                                    ooh shiny commenting  female          0   \n",
       "1       wuts parade suked band battle kicked ass jims ...    male          0   \n",
       "2       anymore concerned everyday bold faced liar ahe...  female          1   \n",
       "3                                 roof sunset posted paul    male          1   \n",
       "4       gawd luv nanny absolutely greatest woman earth...  female          1   \n",
       "...                                                   ...     ...        ...   \n",
       "526807  write injuries sand kindnesses marble french p...    male          2   \n",
       "526808                                       wes dad stan  female          1   \n",
       "526809  prefer calling nice guy fact obviously carried...    male          0   \n",
       "526810  angela othello noah shaved head short hair sho...  female          0   \n",
       "526811  keeping short busy wasting ways online hobbies...  female          2   \n",
       "\n",
       "        word_count  has_emoticon  has_punctuation  has_hope  has_hehe  \\\n",
       "0                3             0                0         0         0   \n",
       "1               15             0                0         0         0   \n",
       "2               25             0                0         1         0   \n",
       "3                4             0                0         0         0   \n",
       "4              204             0                0         0         0   \n",
       "...            ...           ...              ...       ...       ...   \n",
       "526807          10             0                0         0         0   \n",
       "526808           3             0                0         0         0   \n",
       "526809          41             0                0         0         0   \n",
       "526810          25             0                0         0         0   \n",
       "526811          83             0                0         0         0   \n",
       "\n",
       "        has_weeks  ...  has_taking  has_bill  has_hey  has_saturday  \\\n",
       "0               0  ...           0         0        0             0   \n",
       "1               0  ...           0         0        0             0   \n",
       "2               0  ...           0         0        0             0   \n",
       "3               0  ...           0         0        0             0   \n",
       "4               0  ...           0         0        0             0   \n",
       "...           ...  ...         ...       ...      ...           ...   \n",
       "526807          0  ...           0         0        0             0   \n",
       "526808          0  ...           0         0        0             0   \n",
       "526809          0  ...           0         0        0             0   \n",
       "526810          0  ...           0         0        0             0   \n",
       "526811          0  ...           0         0        0             0   \n",
       "\n",
       "        has_remember  has_party  has_walking  has_share  has_brother  has_URL  \n",
       "0                  0          0            0          0            0        0  \n",
       "1                  0          1            0          0            0        0  \n",
       "2                  0          1            0          0            0        0  \n",
       "3                  0          0            0          0            0        0  \n",
       "4                  0          0            0          0            0        0  \n",
       "...              ...        ...          ...        ...          ...      ...  \n",
       "526807             0          0            0          0            0        0  \n",
       "526808             0          0            0          0            0        0  \n",
       "526809             0          0            0          0            0        0  \n",
       "526810             0          0            0          0            0        0  \n",
       "526811             0          0            0          0            0        0  \n",
       "\n",
       "[503897 rows x 547 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset with additional features (TODO: metti tutto insieme nel file di preprocessing)\n",
    "features = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/train_features_paper.pkl')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>embedding</th>\n",
       "      <th>age_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thabo admits defeat quiet diplomacy mbeki stat...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.06341848, -0.00037825145, -0.016663542, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brainbench welcomes millionth subscriber annou...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.060284454, -0.055480707, 0.00930549, -0.01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air jerusalem dry heavy sense weight shoulders...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.010743902, 0.07802959, 0.06183355, 0.068029...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embarassing sensitive wish sensitive thick ski...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.062046394, -0.057088595, 0.06919461, 0.053...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glass artist firing excuse research fused glas...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0025419437, -0.03190446, 0.014133493, -0.0...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131698</th>\n",
       "      <td>em hope job sounds million times drinks times ...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.032921113, -0.07573543, 0.013446527, -0.04...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131699</th>\n",
       "      <td>blood pressure high blood work whatnot tuesday...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.07032361, -0.0056662075, 0.049271625, -0.0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131700</th>\n",
       "      <td>hoping news news absence inspiration enthusias...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.01240979, 0.009257221, -0.009716861, 0.0415...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131701</th>\n",
       "      <td>slow couple egregious errors anna told wanted ...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.034908127, 0.02392359, 0.0663985, 0.002502...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131702</th>\n",
       "      <td>arafat offices gaza burned abc news dozens mil...</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.036015436, -0.01788257, 0.025198337, -0.013...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130378 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  age  gender  \\\n",
       "0       thabo admits defeat quiet diplomacy mbeki stat...   27       1   \n",
       "1       brainbench welcomes millionth subscriber annou...   25       1   \n",
       "2       air jerusalem dry heavy sense weight shoulders...   23       0   \n",
       "3       embarassing sensitive wish sensitive thick ski...   25       0   \n",
       "4       glass artist firing excuse research fused glas...   38       0   \n",
       "...                                                   ...  ...     ...   \n",
       "131698  em hope job sounds million times drinks times ...   26       0   \n",
       "131699  blood pressure high blood work whatnot tuesday...   27       0   \n",
       "131700  hoping news news absence inspiration enthusias...   24       0   \n",
       "131701  slow couple egregious errors anna told wanted ...   36       1   \n",
       "131702  arafat offices gaza burned abc news dozens mil...   48       1   \n",
       "\n",
       "                                                embedding  age_class  \n",
       "0       [-0.06341848, -0.00037825145, -0.016663542, -0...          1  \n",
       "1       [-0.060284454, -0.055480707, 0.00930549, -0.01...          1  \n",
       "2       [0.010743902, 0.07802959, 0.06183355, 0.068029...          1  \n",
       "3       [-0.062046394, -0.057088595, 0.06919461, 0.053...          1  \n",
       "4       [-0.0025419437, -0.03190446, 0.014133493, -0.0...          2  \n",
       "...                                                   ...        ...  \n",
       "131698  [-0.032921113, -0.07573543, 0.013446527, -0.04...          1  \n",
       "131699  [-0.07032361, -0.0056662075, 0.049271625, -0.0...          1  \n",
       "131700  [0.01240979, 0.009257221, -0.009716861, 0.0415...          1  \n",
       "131701  [-0.034908127, 0.02392359, 0.0663985, 0.002502...          2  \n",
       "131702  [0.036015436, -0.01788257, 0.025198337, -0.013...          2  \n",
       "\n",
       "[130378 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_pickle('/Users/simonefacchiano/Desktop/Data Science/SL/Project/SL-Final-Project/test_embedding.pkl')\n",
    "\n",
    "test['gender'] = test['gender'].map({'male': 1, 'female': 0})\n",
    "test['age_class'] = pd.cut(\n",
    "        test[\"age\"],\n",
    "        bins=[12, 18, 28, 50],\n",
    "        labels=[0, 1, 2]\n",
    "    ).astype(\"int\")\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the labels for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat embedding and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(embedding, features, left_index=True, right_index=True)\n",
    "data = data[data.post.notna()]\n",
    "\n",
    "data['gender'] = data['gender'].map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows with specific word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.5872e+04, 1.6030e+04, 4.6920e+03, 1.7430e+03, 7.1400e+02,\n",
       "        3.3900e+02, 2.0200e+02, 1.1400e+02, 7.3000e+01, 5.7000e+01]),\n",
       " array([  0. ,  99.9, 199.8, 299.7, 399.6, 499.5, 599.4, 699.3, 799.2,\n",
       "        899.1, 999. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data[data.word_count < 1000].word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len( data[data.word_count < 3] ))\n",
    "print(len( data[data.word_count >= 1000] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480380, 548)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rimuovi le righe con word count inferiore a 5 o superiore a 1000\n",
    "data = data[(data['word_count'] >= 3) & (data['word_count'] <= 1000)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model: Predicting the Gender of the author\n",
    "\n",
    "Note: the genders are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first identify the feature matrix and the labels\n",
    "\n",
    "X = data['embedding'].to_list() # ,'has_young_word', 'word_count', 'has_emoticon', 'has_punctuation', 'has_URL'\n",
    "# X = pd.DataFrame(embedding['embedding'].to_list(), columns=[f'embedding_{i+1}' for i in range(384)])\n",
    "# X = pd.concat([X, features], axis = 1)\n",
    "y = data['gender'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set has 384304 rows, while the validation set contains 96076 rows: 80% vs 20%.\n"
     ]
    }
   ],
   "source": [
    "# Create the train & validation sets\n",
    "# In this way, every operation of fine tuning will depend on the data observed in the validation, while the final assessment for the quality of the model will be made on the test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y) # stratification on the y to avoid class imbalancement\n",
    "\n",
    "print(f'The train set has {len(X_train)} rows, while the validation set contains {len(X_val)} rows: 80% vs 20%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start with a very simple Logistic Regression to see how it works\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy  : 0.6548045297472834\n",
      "Logistic Regression Precision : 0.66300494641385\n",
      "Logistic Regression Recall    : 0.6567380519772166\n",
      "Logistic Regression Balanced Score : 0.6547657303820426\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = lr.predict(X_val)\n",
    "\n",
    "print(f'Logistic Regression Accuracy  : {metrics.accuracy_score(y_val, predicted)}')\n",
    "print(f'Logistic Regression Precision : {metrics.precision_score(y_val, predicted)}')\n",
    "print(f'Logistic Regression Recall    : {metrics.recall_score(y_val, predicted)}')\n",
    "\n",
    "print(f'Logistic Regression Balanced Score : {metrics.balanced_accuracy_score(y_val, predicted)}')\n",
    "\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30931, 16162],\n",
       "       [17047, 31936]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy  : 0.6479390694749114\n",
      "Logistic Regression Balanced Score : 0.6476627370093713\n"
     ]
    }
   ],
   "source": [
    "X_train = data['embedding'].to_list()\n",
    "y_train = data['gender'].to_list()\n",
    "\n",
    "X_test = test['embedding'].to_list()\n",
    "y_test = test['gender'].to_list()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted = lr.predict(X_test)\n",
    "\n",
    "print(f'Logistic Regression Accuracy  : {metrics.accuracy_score(y_test, predicted)}')\n",
    "print(f'Logistic Regression Balanced Score : {metrics.balanced_accuracy_score(y_test, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [10],\n",
    "    'penalty': ['l1', 'l2']\n",
    "    #'max_iter': list(range(100, 800, 200)),\n",
    "    #'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "lr_search = GridSearchCV(lr, param_grid=param_grid, refit = True, verbose = 3, cv=5)\n",
    "\n",
    "# fitting the model for grid search \n",
    "lr_search.fit(X_train, y_train)\n",
    "lr_search.best_params_\n",
    "# summarize\n",
    "print('Best Accuracy: %.3f' % lr_search.best_score_)\n",
    "print('Config: %s' % lr_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy : 0.6499049730757048\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 10, penalty = 'l2')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted = lr.predict(X_val)\n",
    "\n",
    "print(f'Logistic Regression Accuracy : {metrics.accuracy_score(y_val, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = small_data['embedding'].to_list() # ,'has_young_word', 'word_count', 'has_emoticon', 'has_punctuation', 'has_URL'\n",
    "y = small_data['gender'].to_list()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost (different learning rate)\n",
    "learning_rate_range = np.arange(0.01, 1, 0.1)\n",
    "val_XG = [] \n",
    "train_XG = []\n",
    "for lr in learning_rate_range:\n",
    "    xgb_classifier = xgb.XGBClassifier(eta = lr)\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    train_XG.append(xgb_classifier.score(X_train, y_train))\n",
    "    val_XG.append(xgb_classifier.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(learning_rate_range, train_XG, c='orange', label='Train')\n",
    "plt.plot(learning_rate_range, val_XG, c='m', label='Test')\n",
    "plt.xlabel('Learning rate')\n",
    "plt.xticks(learning_rate_range)\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.ylim(0.6, 1)\n",
    "plt.legend(prop={'size': 12}, loc=3)\n",
    "plt.title('Accuracy score vs. Learning rate of XGBoost', size=14)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we add features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['embedding'].to_list(), columns=[f'embedding_{i+1}' for i in range(384)])\n",
    "X = pd.concat([X.reset_index(drop=True), data[data.columns.difference(['embedding', 'post', 'clean_post', 'gender', 'age_class', 'has_capital'])].reset_index(drop=True)], axis = 1) \n",
    "\n",
    "# X = pd.DataFrame(data[data.columns.difference(['embedding', 'post', 'clean_post', 'gender', 'age_class', 'has_capital'])])\n",
    "\n",
    "y = data['gender'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy : 0.653014241353464\n",
      "Logistic Regression Precision: 0.6494701059788043\n",
      "Logistic Regression Recall   : 0.6858832224685883\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(X_val)\n",
    "\n",
    "print(f'Logistic Regression Accuracy : {metrics.accuracy_score(y_val, predicted)}')\n",
    "print(f'Logistic Regression Precision: {metrics.precision_score(y_val, predicted)}')\n",
    "print(f'Logistic Regression Recall   : {metrics.recall_score(y_val, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6159, 3353],\n",
       "       [3465, 6309]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>word_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104274</th>\n",
       "      <td>loophole h bush administration economic stimul...</td>\n",
       "      <td>417.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8574</th>\n",
       "      <td>know p j best thing world complicated right wr...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74313</th>\n",
       "      <td>year star wars fan film awards finalists fate ...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95729</th>\n",
       "      <td>example pictures</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103380</th>\n",
       "      <td>section home best loyal passionate soccer fans...</td>\n",
       "      <td>931.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104044</th>\n",
       "      <td>found today stories going published new yinzer...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92215</th>\n",
       "      <td>apologies sparta collapse looking recent posts...</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>loads things write aabout right right feel lik...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>look people drugs drink excessively sex outsid...</td>\n",
       "      <td>561.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91979</th>\n",
       "      <td>t shirt says today misadventures css coding le...</td>\n",
       "      <td>297.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19286 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  word_count  gender  \\\n",
       "104274  loophole h bush administration economic stimul...       417.0       1   \n",
       "8574    know p j best thing world complicated right wr...       131.0       0   \n",
       "74313   year star wars fan film awards finalists fate ...        36.0       1   \n",
       "95729                                    example pictures         9.0       1   \n",
       "103380  section home best loyal passionate soccer fans...       931.0       1   \n",
       "...                                                   ...         ...     ...   \n",
       "104044  found today stories going published new yinzer...        88.0       0   \n",
       "92215   apologies sparta collapse looking recent posts...       645.0       1   \n",
       "3619    loads things write aabout right right feel lik...        49.0       0   \n",
       "29998   look people drugs drink excessively sex outsid...       561.0       1   \n",
       "91979   t shirt says today misadventures css coding le...       297.0       1   \n",
       "\n",
       "        gender_pred  \n",
       "104274            1  \n",
       "8574              0  \n",
       "74313             1  \n",
       "95729             1  \n",
       "103380            1  \n",
       "...             ...  \n",
       "104044            1  \n",
       "92215             0  \n",
       "3619              0  \n",
       "29998             1  \n",
       "91979             1  \n",
       "\n",
       "[19286 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val = data.iloc[X_val.index][['post', 'word_count', 'gender']]\n",
    "data_val['gender_pred'] = predicted\n",
    "\n",
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>word_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34571</th>\n",
       "      <td>yoz todae skl le actualyl bad la onli dat mi v...</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100221</th>\n",
       "      <td>working like hell got low self respect level j...</td>\n",
       "      <td>382.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65813</th>\n",
       "      <td>real holy time yesterday mike cope mentions ki...</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12907</th>\n",
       "      <td>mobile phone closed monday long irritating sto...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89444</th>\n",
       "      <td>avenged sevenfold amazing band man ought cd go...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69575</th>\n",
       "      <td>xe com universal currency converter tm</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17456</th>\n",
       "      <td>ok post tell aabout title late test results ex...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82432</th>\n",
       "      <td>imagine life time</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104044</th>\n",
       "      <td>found today stories going published new yinzer...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92215</th>\n",
       "      <td>apologies sparta collapse looking recent posts...</td>\n",
       "      <td>645.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6818 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  word_count  gender  \\\n",
       "34571   yoz todae skl le actualyl bad la onli dat mi v...       203.0       1   \n",
       "100221  working like hell got low self respect level j...       382.0       1   \n",
       "65813   real holy time yesterday mike cope mentions ki...       383.0       1   \n",
       "12907   mobile phone closed monday long irritating sto...        34.0       0   \n",
       "89444   avenged sevenfold amazing band man ought cd go...        44.0       0   \n",
       "...                                                   ...         ...     ...   \n",
       "69575              xe com universal currency converter tm         8.0       0   \n",
       "17456   ok post tell aabout title late test results ex...       152.0       1   \n",
       "82432                                   imagine life time        14.0       0   \n",
       "104044  found today stories going published new yinzer...        88.0       0   \n",
       "92215   apologies sparta collapse looking recent posts...       645.0       1   \n",
       "\n",
       "        gender_pred  \n",
       "34571             0  \n",
       "100221            0  \n",
       "65813             0  \n",
       "12907             1  \n",
       "89444             1  \n",
       "...             ...  \n",
       "69575             1  \n",
       "17456             0  \n",
       "82432             1  \n",
       "104044            1  \n",
       "92215             0  \n",
       "\n",
       "[6818 rows x 4 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val[data_val.gender != data_val.gender_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.1s\n",
      "[CV 2/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=0.1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.637 total time=   1.5s\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.633 total time=   1.5s\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.631 total time=   1.5s\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.625 total time=   1.5s\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.636 total time=   1.6s\n",
      "[CV 1/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....................C=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...................C=1, penalty=l2;, score=0.637 total time=   1.6s\n",
      "[CV 2/5] END ...................C=1, penalty=l2;, score=0.638 total time=   1.5s\n",
      "[CV 3/5] END ...................C=1, penalty=l2;, score=0.629 total time=   1.5s\n",
      "[CV 4/5] END ...................C=1, penalty=l2;, score=0.625 total time=   1.4s\n",
      "[CV 5/5] END ...................C=1, penalty=l2;, score=0.635 total time=   1.4s\n",
      "[CV 1/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=10, penalty=l2;, score=0.638 total time=   1.6s\n",
      "[CV 2/5] END ..................C=10, penalty=l2;, score=0.632 total time=   1.5s\n",
      "[CV 3/5] END ..................C=10, penalty=l2;, score=0.629 total time=   1.4s\n",
      "[CV 4/5] END ..................C=10, penalty=l2;, score=0.625 total time=   1.4s\n",
      "[CV 5/5] END ..................C=10, penalty=l2;, score=0.637 total time=   1.5s\n",
      "[CV 1/5] END ....................C=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....................C=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....................C=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....................C=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....................C=50, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..................C=50, penalty=l2;, score=0.638 total time=   1.5s\n",
      "[CV 2/5] END ..................C=50, penalty=l2;, score=0.635 total time=   1.5s\n",
      "[CV 3/5] END ..................C=50, penalty=l2;, score=0.627 total time=   1.4s\n",
      "[CV 4/5] END ..................C=50, penalty=l2;, score=0.627 total time=   1.5s\n",
      "[CV 5/5] END ..................C=50, penalty=l2;, score=0.635 total time=   1.4s\n",
      "[CV 1/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...................C=100, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .................C=100, penalty=l2;, score=0.637 total time=   1.6s\n",
      "[CV 2/5] END .................C=100, penalty=l2;, score=0.631 total time=   1.5s\n",
      "[CV 3/5] END .................C=100, penalty=l2;, score=0.629 total time=   1.4s\n",
      "[CV 4/5] END .................C=100, penalty=l2;, score=0.624 total time=   1.4s\n",
      "[CV 5/5] END .................C=100, penalty=l2;, score=0.638 total time=   1.5s\n",
      "[CV 1/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..................C=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ................C=1000, penalty=l2;, score=0.636 total time=   1.5s\n",
      "[CV 2/5] END ................C=1000, penalty=l2;, score=0.635 total time=   1.5s\n",
      "[CV 3/5] END ................C=1000, penalty=l2;, score=0.629 total time=   1.5s\n",
      "[CV 4/5] END ................C=1000, penalty=l2;, score=0.624 total time=   1.5s\n",
      "[CV 5/5] END ................C=1000, penalty=l2;, score=0.635 total time=   1.4s\n",
      "Mean Accuracy: 0.633\n",
      "Config: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 50, 100, 1000],\n",
    "    'penalty': ['l1', 'l2'] #,\n",
    "    # 'max_iter': list(range(100,800,100)),\n",
    "    #'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "lr_search = GridSearchCV(lr, param_grid=param_grid, refit = True, verbose = 3, cv=5)\n",
    "\n",
    "# fitting the model for grid search \n",
    "lr_search.fit(X_train , y_train)\n",
    "lr_search.best_params_\n",
    "# summarize\n",
    "print('Mean Accuracy: %.3f' % lr_search.best_score_)\n",
    "print('Config: %s' % lr_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 1, penalty = 'l2')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy after Regularization : 0.63975\n",
      "Logistic Precision after Regularization: 0.6488718775181306\n",
      "Logistic Recall after Regularization   : 0.6339927172522389\n"
     ]
    }
   ],
   "source": [
    "predicted = lr.predict(X_val)\n",
    "\n",
    "print(f'Logistic Accuracy after Regularization : {metrics.accuracy_score(y_val, predicted)}')\n",
    "print(f'Logistic Precision after Regularization: {metrics.precision_score(y_val, predicted)}')\n",
    "print(f'Logistic Recall after Regularization   : {metrics.recall_score(y_val, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confrontare diversi modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [03:15<06:31, 195.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: Mean Accuracy = 61.73%; Mean F1-macro = 61.65%; Mean recall-macro = 61.67%; Mean precision-macro = 61.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [03:42<01:36, 96.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC: Mean Accuracy = 64.03%; Mean F1-macro = 64.02%; Mean recall-macro = 64.03%; Mean precision-macro = 64.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:06<00:00, 82.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Mean Accuracy = 63.95%; Mean F1-macro = 63.95%; Mean recall-macro = 63.95%; Mean precision-macro = 63.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#  defining models and associated parameters\n",
    "models = [RandomForestClassifier(n_estimators = 100, max_depth=5, random_state=42), \n",
    "          LinearSVC(random_state=42),\n",
    "          LogisticRegression(random_state=42)]\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1) # With StratifiedKFold, the folds are made by preserving the percentage of samples for each class.\n",
    "\n",
    "scoring = ['accuracy', 'f1_macro', 'recall_macro', 'precision_macro']\n",
    "\n",
    "#  iterative loop print metrics from each model\n",
    "for model in tqdm(models):\n",
    "    model_name = model.__class__.__name__\n",
    "    result = cross_validate(model, X_train, y_train, cv=kf, scoring=scoring)\n",
    "    print(\"%s: Mean Accuracy = %.2f%%; Mean F1-macro = %.2f%%; Mean recall-macro = %.2f%%; Mean precision-macro = %.2f%%\" \n",
    "          % (model_name, \n",
    "             result['test_accuracy'].mean()*100, \n",
    "             result['test_f1_macro'].mean()*100, \n",
    "             result['test_recall_macro'].mean()*100, \n",
    "             result['test_precision_macro'].mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['embedding'].to_list() # ,'has_young_word', 'word_count', 'has_emoticon', 'has_punctuation', 'has_URL'\n",
    "# X = pd.DataFrame(embedding['embedding'].to_list(), columns=[f'embedding_{i+1}' for i in range(384)])\n",
    "# X = pd.concat([X, features], axis = 1)\n",
    "y = data['age_class'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set has 74710 rows, while the validation set contains 18678 rows: 80% vs 20%.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y) # stratification on the y to avoid class imbalancement\n",
    "\n",
    "print(f'The train set has {len(X_train)} rows, while the validation set contains {len(X_val)} rows: 80% vs 20%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight={0: 1.1, 1: 1, 2: 1.25},\n",
       "                   multi_class='multinomial')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', class_weight = {0: 1.1, 1: 1, 2: 1.25})\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Regression Accuracy : 0.6050969054502623\n",
      "Multinomial Logistic Regression Balanced Score : 0.5389280295681095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "predicted = model.predict(X_val)\n",
    "\n",
    "print(f'Multinomial Logistic Regression Accuracy : {metrics.accuracy_score(y_val, predicted)}')\n",
    "print(f'Multinomial Logistic Regression Balanced Score : {metrics.balanced_accuracy_score(y_val, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4085, 2068,  198],\n",
       "       [1720, 6314,  778],\n",
       "       [ 395, 2261,  859]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy  : 0.6007301845403366\n",
      "Logistic Regression Balanced Score : 0.5106510235753629\n"
     ]
    }
   ],
   "source": [
    "X_train = data['embedding'].to_list()\n",
    "y_train = data['age_class'].to_list()\n",
    "\n",
    "X_test = test['embedding'].to_list()\n",
    "y_test = test['age_class'].to_list()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted = lr.predict(X_test)\n",
    "\n",
    "print(f'Logistic Regression Accuracy  : {metrics.accuracy_score(y_test, predicted)}')\n",
    "print(f'Logistic Regression Balanced Score : {metrics.balanced_accuracy_score(y_test, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we add the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_post', 'has_emoticon', 'has_punctuation', 'has_URL',\n",
       "       'has_capital', 'girl_word', 'boy_word', 'young_word', 'medium_word',\n",
       "       'old_word', 'word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['embedding'].to_list(), columns=[f'embedding_{i+1}' for i in range(384)])\n",
    "X = pd.concat([X.reset_index(drop=True), data[data.columns.difference(['embedding', 'post', 'clean_post', 'gender', 'age_class', 'has_capital'])].reset_index(drop=True)], axis = 1) \n",
    "\n",
    "y = data['age_class'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set has 74710 rows, while the validation set contains 18678 rows: 80% vs 20%.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y) # stratification on the y to avoid class imbalancement\n",
    "\n",
    "print(f'The train set has {len(X_train)} rows, while the validation set contains {len(X_val)} rows: 80% vs 20%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Regression Accuracy : 0.6038655102259343\n",
      "Multinomial Logistic Regression Accuracy : 0.5015687138751751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\n",
    "\n",
    "predicted = model.predict(X_val)\n",
    "\n",
    "print(f'Multinomial Logistic Regression Accuracy : {metrics.accuracy_score(y_val, predicted)}')\n",
    "print(f'Multinomial Logistic Regression Accuracy : {metrics.balanced_accuracy_score(y_val, predicted)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4110, 2559,  120],\n",
       "       [1573, 7404,  486],\n",
       "       [ 339, 2803,  606]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
